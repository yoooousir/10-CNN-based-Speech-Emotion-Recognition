## 프로젝트 개요

Convolutional Neural Networks (CNN)를 바탕으로 한 음성 기반 감정 인식 모델을 구성하고 훈련시킨 프로젝트로, 데이터 전처리, 특징 추출 및 가공, 모델 학습을 수행하며 오디오 파일을 일관되게 처리하는 종합 파이프라인을 개발하고, Accuracy(정확도), Precision(정밀도), Recall(재현율), F1 Score, Confusion Matrix를 통해 모델의 성능을 평가하였습니다.

### 주요 기능 및 작업 흐름

- **데이터셋 통합**: RAVDESS, CREMA-D, SAVEE, TESS와 같은 다양한 감정 음성 데이터셋을 통합하여 활용함.
- **전처리**: "노이즈 주입", "피치 조정", "스트레칭"을 통해 오디오 데이터 증강을 수행했으며, "널(null) 값 처리"와 "중복 제거"를 처리함.
- **감정 분류**: 'angry', 'calm', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'의 카테고리로 감정을 분류함.
- **특징 공학**: "멜 주파수 켑스트럼 계수(MFCC)", "루트 평균 제곱값(RMS)", "영 교차율(ZCR)"과 같은 오디오 특징을 추출함.
- **모델 구조 및 학습**: 10층으로 구성된 CNN 모델로, 1D 합성곱 계층, 배치 정규화, 맥스 풀링을 포함함. ReLU 활성화를 사용하는 여러 Conv1D 계층과 분류를 위한 Dense 계층이 포함되며, 약 6.15M 개의 학습 가능한 파라미터를 통해 효율적으로 감정을 학습함.

### 사용 방법

1. 지정된 디렉토리에 오디오 데이터셋 준비.
2. 전처리 및 특징 추출 스크립트 실행.
3. 모델 학습 및 성능 평가.
